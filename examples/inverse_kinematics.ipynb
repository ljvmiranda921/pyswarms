{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving the Inverse Kinematics problem using Particle Swarm Optimization\n",
    "====================================\n",
    "\n",
    "In this example, we are going to use the `pyswarms` library to solve a 6-DOF (Degrees of Freedom) Inverse Kinematics (IK) problem by treating it as an optimization problem. We will use the `pyswarms` library to find an *optimal* solution from a set of candidate solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Change directory to access the pyswarms module\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Python version: 3.6.0 (v3.6.0:41df79263a11, Dec 23 2016, 07:18:10) [MSC v.1900 32 bit (Intel)]\n"
     ]
    }
   ],
   "source": [
    "print('Running on Python version: {}'.format(sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "\n",
    "# Import PySwarms\n",
    "import pyswarms as ps\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "  table {margin-left: 0 !important;}\n",
       "</style>\n",
       "# Styling for the text below"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "</style>\n",
    "# Styling for the text below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "======\n",
    "\n",
    "Inverse Kinematics is one of the most challenging problems in robotics. The problem involves finding an optimal *pose* for a manipulator given the position of the end-tip effector as opposed to forward kinematics, where the end-tip position is sought given the pose or joint configuration. Normally, this position is expressed as a point in a coordinate system (e.g., in a Cartesian system with $x$, $y$ and $z$ coordinates). However, the pose of the manipulator can also be expressed as the collection of joint variables that describe the angle of bending or twist (in revolute joints) or length of extension (in prismatic joints).\n",
    "\n",
    "IK is particularly difficult because an abundance of solutions can arise. Intuitively, one can imagine that a robotic arm can have multiple ways of reaching through a certain point. It's the same when you touch the table and move your arm without moving the point you're touching the table at. Moreover, the calculation of these positions can be very difficult. Simple solutions can be found for 3-DOF manipulators but trying to solve the problem for 6 or even more DOF can lead to challenging algebraic problems.\n",
    "\n",
    "IK as an Optimization Problem\n",
    "===============\n",
    "\n",
    "In this implementation, we are going to use a *6-DOF Stanford Manipulator* with 5 revolute joints and 1 prismatic joint. Furthermore, the constraints of the joints are going to be as follows:\n",
    "\n",
    "| Parameters | Lower Boundary | Upper Boundary |\n",
    "|:---:|:----------------:|:----------------:|\n",
    "|$\\theta_1$  | $-\\pi$         | $\\pi$          |\n",
    "|$\\theta_2$  |$-\\frac{\\pi}{2}$| $\\frac{\\pi}{2}$|\n",
    "|$d_3$       | $1$            | $3$            |\n",
    "|$\\theta_4$  | $-\\pi$         | $\\pi$          |\n",
    "|$\\theta_5$  |$-\\frac{5\\pi}{36}$|$\\frac{5\\pi}{36}$|\n",
    "|$\\theta_6$  | $-\\pi$         | $\\pi$          |\n",
    "\n",
    "**Table 1**: *Physical constraints for the joint variables*\n",
    "\n",
    "Now, if we are given an *end-tip position* (in this case a $xyz$ coordinate) we need to find the optimal parameters with the constraints imposed in **Table 1**. These conditions are then sufficient in order to treat this problem as an optimization problem. We define our parameter vector $\\mathbf{X}$ as follows:\n",
    "\n",
    "$$\\mathbf{X}\\,:=\\, [ \\, \\theta_1 \\quad \\theta_2 \\quad d_3\\ \\quad \\theta_4 \\quad \\theta_5 \\, ]$$\n",
    "\n",
    "And for our end-tip position we define the target vector $\\mathbf{T}$ as:\n",
    "\n",
    "$$\\mathbf{T}\\,:=\\, [\\, T_x \\quad T_y \\quad T_z \\,]$$\n",
    "\n",
    "We can then start implementing our optimization algorithm.\n",
    "\n",
    "Initializing the Swarm\n",
    "===========\n",
    "\n",
    "The main idea for PSO is that we set a swarm $\\mathbf{S}$ composed of particles $\\mathbf{P}_n$ into a search space in order to find the optimal solution. The movement of the swarm depends on the cognitive ($c_1$) and social ($c_2$) of all the particles. The cognitive component speaks of the particle's bias towards its personal best from its past experience (i.e., how attracted it is to its own best position). The social component controls how the particles are attracted to the best score found by the swarm (i.e., the global best). High $c_1$ paired with low $c_2$ values can often cause the swarm to stagnate. The inverse can cause the swarm to converge too fast, resulting in suboptimal solutions.\n",
    "\n",
    "We define our particle $\\mathbf{P}$ as:\n",
    "\n",
    "$$\\mathbf{P}\\,:=\\,\\mathbf{X}$$\n",
    "\n",
    "And the swarm as being composed of $N$ particles with certain positions at a timestep $t$:\n",
    "\n",
    "$$\\mathbf{S}_t\\,:=\\,[\\,\\mathbf{P}_1\\quad\\mathbf{P}_2\\quad ... \\quad\\mathbf{P}_N\\,]$$\n",
    "\n",
    "In this implementation, we designate $\\mathbf{P}_1$ as the initial configuration of the manipulator at the zero-position. This means that the angles are equal to 0 and the link offset is also zero. We then generate the $N-1$ particles using a uniform distribution which is controlled by the hyperparameter $\\epsilon$.\n",
    "\n",
    "Finding the global optimum\n",
    "=============\n",
    "\n",
    "In order to find the global optimum, the swarm must be moved. This movement is then translated by an update of the current position given the swarm's velocity $\\mathbf{V}$. That is:\n",
    "\n",
    "$$\\mathbf{S}_{t+1} = \\mathbf{S}_t + \\mathbf{V}_{t+1}$$\n",
    "\n",
    "The velocity is then computed as follows:\n",
    "\n",
    "$$\\mathbf{V}_{t+1} = w\\mathbf{V}_t + c_1 r_1 (\\mathbf{p}_{best} - \\mathbf{p}) + c_2 r_2(\\mathbf{g}_{best} - \\mathbf{p})$$\n",
    "\n",
    "Where $r_1$ and $r_2$ denote random values in the intervall $[0,1]$, $\\mathbf{p}_{best}$ is the best and $\\mathbf{p}$ is the current personal position and $\\mathbf{g}_{best}$ is the best position of all the particles. Moreover, $w$ is the inertia weight that controls the \"memory\" of the swarm's previous position.\n",
    "\n",
    "Preparations\n",
    "------------\n",
    "\n",
    "Let us now see how this works with the `pyswarms` library. We use the point $[-2,2,3]$ as our target for which we want to find an optimal pose of the manipulator. We start by defining a function to get the distance from the current position to the target position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(query, target):\n",
    "    x_dist = (target[0] - query[0])**2\n",
    "    y_dist = (target[1] - query[1])**2\n",
    "    z_dist = (target[2] - query[2])**2\n",
    "    dist = np.sqrt(x_dist + y_dist + z_dist)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the distance function to compute the cost, the further away the more costly the position is.  \n",
    "\n",
    "The optimization algorithm needs some parameters (the swarm size, $c_1$, $c_2$ and $\\epsilon$). For the *options* ($c_1$,$c_2$ and $w$) we have to create a dictionary and for the constraints a tuple with a list of the respective minimal values and a list of the respective maximal values. The rest can be handled with variables. Additionally, we define the joint lengths to be 3 units long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_size = 20\n",
    "dim = 6        # Dimension of X\n",
    "epsilon = 1.0\n",
    "options = {'c1': 1.5, 'c2':1.5, 'w':0.5}\n",
    "\n",
    "constraints = (np.array([-np.pi , -np.pi/2 , 1 , -np.pi , -5*np.pi/36 , -np.pi]),\n",
    "               np.array([np.pi  ,  np.pi/2 , 3 ,  np.pi ,  5*np.pi/36 ,  np.pi]))\n",
    "\n",
    "d1 = d2 = d3 = d4 = d5 = d6 = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain the current position, we need to calculate the matrices of rotation and translation for every joint. Here we use the [Denvait-Hartenberg parameters](https://en.wikipedia.org/wiki/Denavitâ€“Hartenberg_parameters) for that. So we define a function that calculates these. The function uses the rotation angle and the extension $d$ of a prismatic joint as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTransformMatrix(theta, d, a, alpha):\n",
    "    T = np.array([[np.cos(theta) , -np.sin(theta)*np.cos(alpha) ,  np.sin(theta)*np.sin(alpha) , a*np.cos(theta)],\n",
    "                  [np.sin(theta) ,  np.cos(theta)*np.cos(alpha) , -np.cos(theta)*np.sin(alpha) , a*np.sin(theta)],\n",
    "                  [0             ,  np.sin(alpha)               ,  np.cos(alpha)               , d              ],\n",
    "                  [0             ,  0                           ,  0                           , 1              ]\n",
    "                 ])\n",
    "    return T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the transformation matrix to obtain the end tip position. For this we create another function that takes our vector $\\mathbf{X}$ with the joint variables as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_tip_position(params):\n",
    "    # Create the transformation matrices for the respective joints\n",
    "    t_00 = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]])\n",
    "    t_01 = getTransformMatrix(params[0] , d2        , 0 , -np.pi/2)\n",
    "    t_12 = getTransformMatrix(params[1] , d2        , 0 , -np.pi/2)\n",
    "    t_23 = getTransformMatrix(0         , params[2] , 0 , -np.pi/2)\n",
    "    t_34 = getTransformMatrix(params[3] , d4        , 0 , -np.pi/2)\n",
    "    t_45 = getTransformMatrix(params[4] , 0         , 0 ,  np.pi/2)\n",
    "    t_56 = getTransformMatrix(params[5] , d6        ,0  ,  0)\n",
    "\n",
    "    # Get the overall transformation matrix\n",
    "    end_tip_m = t_00.dot(t_01).dot(t_12).dot(t_23).dot(t_34).dot(t_45).dot(t_56)\n",
    "    \n",
    "    # The coordinates of the end tip are the 3 upper entries in the 4th column\n",
    "    pos = np.array([end_tip_m[0,3],end_tip_m[1,3],end_tip_m[2,3]])\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need to prepare in order to run the algorithm is the actual function that we want to optimize. We just need to calculate the distance between the position of each swarm particle and the target point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_func(X):\n",
    "    n_particles = X.shape[0]  # number of particles\n",
    "    target = np.array([-2,2,3])\n",
    "    dist = [distance(get_end_tip_position(X[i]), target) for i in range(n_particles)]\n",
    "    return np.array(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the algorithm\n",
    "----------------------\n",
    "\n",
    "Braced with these preparations we can finally start using the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyswarms.single.global_best:Iteration 1/1000, cost: 0.9638223076369133\n",
      "INFO:pyswarms.single.global_best:Iteration 101/1000, cost: 2.5258875519324167e-07\n",
      "INFO:pyswarms.single.global_best:Iteration 201/1000, cost: 4.7236564972673785e-14\n",
      "INFO:pyswarms.single.global_best:Iteration 301/1000, cost: 0.0\n",
      "INFO:pyswarms.single.global_best:Iteration 401/1000, cost: 0.0\n",
      "INFO:pyswarms.single.global_best:Iteration 501/1000, cost: 0.0\n",
      "INFO:pyswarms.single.global_best:Iteration 601/1000, cost: 0.0\n",
      "INFO:pyswarms.single.global_best:Iteration 701/1000, cost: 0.0\n",
      "INFO:pyswarms.single.global_best:Iteration 801/1000, cost: 0.0\n",
      "INFO:pyswarms.single.global_best:Iteration 901/1000, cost: 0.0\n",
      "INFO:pyswarms.single.global_best:================================\n",
      "Optimization finished!\n",
      "Final cost: 0.0000\n",
      "Best value: [ -2.182725 1.323111 1.579636 ...]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Call an instance of PSO\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=swarm_size,\n",
    "                                    dimensions=dim,\n",
    "                                    options=options,\n",
    "                                    bounds=constraints)\n",
    "\n",
    "# Perform optimization\n",
    "cost, joint_vars = optimizer.optimize(opt_func, print_step=100, iters=1000, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if the algorithm really worked and test the output for `joint_vars`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.  2.  3.]\n"
     ]
    }
   ],
   "source": [
    "print(get_end_tip_position(joint_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! That's exactly the position we wanted the tip to be in. Of course this example is quite primitive. Some extensions of this idea could involve the consideration of the current position of the manipulator and the amount of rotation and extension in the optimization function such that the result is the path with the least movement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
